{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77a9b9",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore this. It just allows me to scroll in my slides.\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f12afd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Lecture 16:<br>Python Refresh!<br></center></h1><h2><center>Thursday Mar 9 2023<br></center></h2>\n",
    "\n",
    "\n",
    "<center><img src=\"https://devs.lol/uploads/2021/11/meme-dev-humor-python-can-hurt-you-in-other-ways-108.jpg\" width=500 height=500 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eaeccc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Updates\n",
    "\n",
    "### Today\n",
    "* <s>Quiz 9 due Friday</s> - No quiz this week!\n",
    "* HW 4 is fairly short\n",
    "    * Officially due 3/21\n",
    "* Groups for final project on Canvas\n",
    "    * Let me know if something seems wrong.\n",
    "    * I expect you to be able to work civilly and responsibly together.\n",
    "        * But if there is a serious issue, please let me know.\n",
    "* Reach out to your group members (NOT over Spring Break)!\n",
    "     * Discuss:\n",
    "         * Project topic (by Thursday Mar. 23)\n",
    "         * Corpora you plan to use\n",
    "         * Responsibilities of each person\n",
    "\n",
    "\n",
    "### Next week: Spring Break!\n",
    "Relax and get some sun! If you're traveling, be safe!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414bdb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First... specific questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3f82c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# For your final project:\n",
    "* You will need a corpus (or multiple corpora).\n",
    "* You can also look through corpora to get an idea of what sounds interesting to you for final topic inspiration.\n",
    "* Do NOT wait until the last minute to do this!\n",
    "    * Some corpora require authorization to access (time-consuming)\n",
    "    * Or may not be in the format you expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66381e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# You may want to import your own data or a corpus not available through NLTK.\n",
    "\n",
    "* Things to consider:\n",
    "    * How your corpus is formatted.\n",
    "    * File encoding\n",
    "* If this causes a great deal of stress for you:\n",
    "    * Stick with NLTK! There are still a great many corpora we haven't looked at.\n",
    "* Let's review how to open our own files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d26bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's review how to import external corpora\n",
    "\n",
    "### To use non-NLTK data, you need to do either of the following:\n",
    "1. Manually drag the file(s) you are using to your current directory. OR\n",
    "2. Change your current directory to the folder with the file in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b3a11",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os # We need this to look at our location\n",
    "os.listdir('.') # Option 1. Our current directory. This will be wherever your current .py or .ipynb file is.\n",
    "# Mine is messy because I don't want to buy more Dropbox space...\n",
    "# If your file is already in here, great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4747a6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Or 2. You can change your directoy. This needs to match the folder your file is in.\n",
    "os.chdir('/Users/jamillahrodriguez/Desktop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36867c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now you need to read the file into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9dc32",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "English401 = open('LING401English.txt') # This will 'open' the file and save it to a workable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f280dd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "English401String = English401.read() # This will allow us to read that object\n",
    "print(English401String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec1332",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Note: For corpora outside of English.\n",
    "* You may need to worry about encoding (depending on what you're doing)\n",
    "* That doesn't mean you _shouldn't_ do it (in fact, much work is needed on languages other than English)\n",
    "    * But you may need to invest more time (and maybe that's something you do or do not want to do)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd17d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Korean401 = open('LING401Korean.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64ef96",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Korean401String = Korean401.read()\n",
    "print(Korean401String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f6c09",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(Korean401String[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9621a01",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Korean401List = Korean401String.split()\n",
    "[word for word in Korean401List if word.endswith(\"을\") or word.endswith(\"를\")] # This works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cdfd1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Korean401String.count(\"ㄱ\") # This does not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea2f60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Returning to corpora available in NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaaf39e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Corpora we have explored\n",
    "   * Gutenberg\n",
    "       * Many full texts with expired copyrights\n",
    "   * Brown\n",
    "       * A large amount of words - good for morphology and general word stats\n",
    "       * Sorted by genres\n",
    "   * Wordnet\n",
    "       * Great for semantics\n",
    "   * CMU Dictionary\n",
    "       * Great for phonology (not very detailed for phonetics)\n",
    "   * But there's much much more. Remember you can always look through here:\n",
    "       * https://www.nltk.org/nltk_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fadbb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some general functions we have used with corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5009de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5c68f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# .raw() will get the data as it originally was (no fancy stuff done)\n",
    "gutenberg.raw(\"carroll-alice.txt\")[:500] # This will get the first 500 characters of that raw text (including \\n for 'new line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86f24e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Many of the corpora in NLTK have a pre-defined .words() function to get \"words:\n",
    "gutenberg.words(\"carroll-alice.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b98935",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'s\", 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']', 'CHAPTER', 'I', '.', 'Down', 'the', 'Rabbit-Hole', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'and\", 'what', 'is', 'the', 'use', 'of', 'a', 'book', ',', \"'\", 'thought', 'Alice', \"'without\", 'pictures', 'or', 'conversation', '?', \"'\", 'So', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', '(', 'as', 'well', 'as', 'she', 'could', ',', 'for', 'the', 'hot']\n"
     ]
    }
   ],
   "source": [
    "# If you are working with a corpus without this pre-defined function, remember we also have the .word_tokenize() function\n",
    "from nltk.tokenize import word_tokenize\n",
    "aliceWords = word_tokenize(gutenberg.raw(\"carroll-alice.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806df7a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# As well as a pre-defined function to get the sentences:\n",
    "gutenberg.sents(\"carroll-alice.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf5244a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other helpful NLTK functions\n",
    "* These are things you can also use once you've imported your own data as well.\n",
    "* Remember we used the nltk.book package to get example texts.\n",
    "\n",
    "* `.concordance()`: shows word with surrounding contexts (in a visually pleasing way)\n",
    "* `.similar()`: finds words that occur in a similar context\n",
    "* `.common_contexts()`: finds the common contexts between two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bae5f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4baa9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d16ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1298a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d90da9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87500bca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK Group Exercise\n",
    "1. Can you find pairs of words which have quite different meanings across the two texts, such as _monstrous_ in Moby Dick (`text1`) and in Sense and Sensibility (`text2`)?\n",
    "2. Can you find words with common contexts, such as \"monstrous\" and \"very\"? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5852a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "636ef0b1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Brown corpus\n",
    "\n",
    "* Main functions we covered:\n",
    "    * `brown.categories()`: lists available genres (\"categories\") of texts\n",
    "    * `brown.words(categories = \"humor\")`: returns all the words in the humor category\n",
    "* We used this corpus to examine frequency distributions\n",
    "    * `nltk.probability.FreqDist()`: creates a frequency distribution object\n",
    "    * `.hapaxes()`: returns all the words that only appear once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3a774",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "romanceSents = brown.sents(categories = \"romance\")\n",
    "print(romanceSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60af61",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "romanceWords = brown.words(categories = \"romance\")\n",
    "print(romanceWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ce96e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Brown corpus exercise\n",
    "\n",
    "Create a list of hapaxes for romance texts and a list of hapaxes for humor texts. How many words appear as hapaxes for both genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d30094",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "humor = brown.words(categories = \"humor\")\n",
    "humorFdist = nltk.probability.FreqDist(humor)\n",
    "humorHap = humorFdist.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9ccbe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "romance = brown.words(categories = \"romance\")\n",
    "romanceFdist = nltk.probability.FreqDist(romance)\n",
    "romanceHap = romanceFdist.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d7e62",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hapaxOverlap = []\n",
    "\n",
    "for hapax in humorHap:\n",
    "    if hapax in romanceHap:\n",
    "        hapaxOverlap.append(hapax)\n",
    "\n",
    "len(hapaxOverlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9474c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMU Dictionary\n",
    "\n",
    "* Main functions we covered:\n",
    "    * `nltk.corpus.cmudict.entries()`: gets CMU entries as a list of tuples\n",
    "    * `nltk.corpus.cmudict.dict()`: gets CMU entries as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8264a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "pronList = nltk.corpus.cmudict.entries()\n",
    "pronList[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abacb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prondict = nltk.corpus.cmudict.dict()\n",
    "prondict['fire']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30fd1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CMU exercise:\n",
    "\n",
    "Find all the words in the CMU dictionary that begin with a vowel and end with \"NG\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c29fd2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "Vng = []\n",
    "\n",
    "for word, pron in entries:\n",
    "    if pron[0][-1].isdigit() and pron[-1] == \"NG\":\n",
    "        Vng.append(word)\n",
    "        \n",
    "print(Vng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5b54b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wordnet\n",
    "* Main functions we covered:\n",
    "    * `wn.synsets('cat')`: returns set of synonyms for the word 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464ebb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn # Import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21210ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "wn.synsets(\"horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935e0179",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "wn.synset('horse.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761b5fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Wordnet exercise:\n",
    "\n",
    "Let's take a vote. What do you expect, on average, to have more senses?\n",
    "* a. nouns (\"n\")\n",
    "* b. verbs (\"v\")\n",
    "* c. adjectives (\"a\")\n",
    "* d. adverbs (\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d9b051",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The polysemy of a word is the number of senses it has. Using WordNet, we can determine that the noun dog has 7 senses with: `len(wn.synsets('dog', 'n'))`. Compute the average polysemy of nouns, verbs, and adjectives according to WordNet. You can get a list of all the synsets for a part of speech with `list(wn.all_synset(\"n\"))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8779ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Let's start by getting all the lemmas under the category N\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "lemmas_n = list(wn.all_lemma_names(\"n\"))\n",
    "\n",
    "print(len(lemmas_n))\n",
    "print(lemmas_n[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abac688",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# If we wanted to cycle through the N lemmas and count how many total senses there are for all the nouns in Wordnet\n",
    "\n",
    "total_senses = 0\n",
    "for lemma in lemmas_n:\n",
    "    sense = wn.synsets(lemma,\"n\")\n",
    "    total_senses = total_senses + len(sense)\n",
    "    \n",
    "print(total_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808fd17f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Now we should get the average number of senses for nouns\n",
    "total_senses/len(lemmas_n) # Total senses/ total nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2696ed4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How can we convert this to a defined function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a63af4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def avg_senses(pos):\n",
    "    lemmas = list(wn.all_lemma_names(pos))\n",
    "    \n",
    "    total_senses = 0\n",
    "    for lemma in lemmas:\n",
    "        sense = wn.synsets(lemma,pos)\n",
    "        total_senses = total_senses + len(sense)\n",
    "        \n",
    "    return total_senses/len(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca3a8c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(avg_senses(\"n\"))\n",
    "print(avg_senses(\"v\")) # Verbs\n",
    "print(avg_senses(\"a\"))\n",
    "print(avg_senses(\"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd2344",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Happy Spring Break!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
